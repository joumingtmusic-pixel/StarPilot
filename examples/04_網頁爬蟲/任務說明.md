# 🕷️ 網頁爬蟲任務

## 🎯 任務目標

學習如何用自然語言讓 AI 幫你從網頁自動抓取資料。

---

## ⚠️ 重要提醒

爬蟲前請注意：
1. **遵守網站的 robots.txt 規則**
2. **不要過度頻繁請求**（建議加上延遲）
3. **僅用於學習和個人用途**
4. **尊重網站的使用條款**

---

## 💬 與 AI 的對話範例

### 情境 1：抓取網頁文字內容

```
👤：我想抓取這個網頁的文章標題和內容
    網址是：https://example.com/article

🤖：好的！我會幫你：
    1. 訪問網頁
    2. 解析 HTML
    3. 提取標題和內文
    
    正在抓取...
    [完成]
    
    ✅ 抓取成功！
    
    標題：AI 時代的職場技能
    內容：在人工智慧快速發展的今天...
    （共 1,234 字）
    
    要儲存成檔案嗎？

👤：存成 TXT 檔

🤖：已儲存：article_20240320.txt
```

---

### 情境 2：批次抓取多個網頁

```
👤：我有一個 URLs 清單，想批次抓取所有網頁的標題

🤖：好的！請提供 URLs 清單
    可以是：
    - 文字檔（每行一個網址）
    - Excel 檔案
    - 直接貼上網址

👤：在 urls.txt 檔案裡

🤖：了解！我會：
    1. 讀取網址清單
    2. 依序訪問每個網頁
    3. 提取標題
    4. 儲存成 CSV
    5. 每個請求間隔 2 秒（避免過度請求）
    
    正在處理...
    [1/10] https://example1.com → 成功
    [2/10] https://example2.com → 成功
    ...
    [完成]
    
    ✅ 成功抓取 10 個網頁
    - 失敗：0 個
    - 結果：titles_20240320.csv
```

---

### 情境 3：抓取表格資料

```
👤：我想抓取這個網頁上的表格
    https://example.com/data-table

🤖：好的！正在分析網頁結構...
    
    我找到 2 個表格：
    1. 產品價格表（5 行 x 4 列）
    2. 銷售統計表（10 行 x 3 列）
    
    要抓取哪一個？

👤：第 1 個

🤖：正在抓取產品價格表...
    [完成]
    
    ✅ 抓取成功！
    
    預覽：
    | 產品名稱 | 規格 | 價格 | 庫存 |
    |---------|------|------|------|
    | 產品A   | 標準 | 1200 | 50   |
    ...
    
    已儲存：product_table_20240320.xlsx
```

---

### 情境 4：監控網頁變化

```
👤：我想監控這個網頁的價格
    如果價格有變動就通知我

🤖：好的！我會建立一個監控程式：
    1. 定時訪問網頁
    2. 檢查價格變化
    3. 發現變動時記錄
    
    多久檢查一次？

👤：每小時檢查一次

🤖：了解！監控程式已建立
    
    設定：
    - 網址：https://example.com/product
    - 檢查頻率：每小時
    - 監控項目：價格
    
    執行 python monitor.py 啟動監控
    
    [監控中...]
    2024-03-20 10:00 - 價格：NT$ 1,200 (無變化)
    2024-03-20 11:00 - 價格：NT$ 1,150 (下降 NT$ 50) ⚠️
```

---

## 🎓 學到的技巧

1. **網頁結構分析**：了解如何定位要抓取的內容
2. **批次處理**：一次抓取多個網頁
3. **資料清洗**：去除不需要的標籤和格式
4. **錯誤處理**：網頁無法訪問時的應對
5. **禮貌爬蟲**：加入延遲，避免造成伺服器負擔

---

## 🚀 現在輪到你了！

開啟 Copilot Chat (`Ctrl+I` 或 `Cmd+I`)，試著對話：

### 練習 1：抓取單一網頁
```
「幫我抓取 https://example.com 的所有文章標題
 儲存成 TXT 檔案」
```

### 練習 2：抓取表格資料
```
「從 https://example.com/table 抓取表格
 轉換成 Excel 檔案」
```

### 練習 3：批次抓取
```
「我有一個網址清單在 urls.txt
 批次抓取所有網頁的標題和摘要
 儲存成 CSV」
```

### 練習 4：定時爬蟲
```
「建立一個自動化腳本
 每天早上 9 點抓取新聞標題
 儲存到 news_archive 資料夾」
```

---

## 💡 提示

### 如何描述要抓取的內容

**明確指定目標元素**：
```
✅ 好的描述：
「抓取 <div class="article"> 裡的所有文字」
「抓取網頁上所有的產品名稱和價格」

❌ 不好的描述：
「抓取網頁內容」（太籠統）
```

### 常見爬蟲場景

1. **新聞資訊**：標題、內容、發布時間
2. **商品資訊**：名稱、價格、規格、評價
3. **表格資料**：股價、匯率、統計數據
4. **圖片下載**：批次下載網頁上的圖片
5. **監控變化**：價格、庫存、內容更新

### 爬蟲的黃金法則

1. **先檢查 API**：有些網站提供官方 API，優先使用
2. **加上延遲**：每個請求間隔 1-2 秒
3. **設定 User-Agent**：模擬瀏覽器訪問
4. **錯誤重試**：網路不穩定時自動重試
5. **記錄日誌**：方便追蹤和除錯

---

## 🛠️ 常用爬蟲技術

### 1. 簡單網頁爬蟲
```
適用：靜態 HTML 網頁
工具：requests + BeautifulSoup
範例：新聞文章、部落格內容
```

### 2. 動態網頁爬蟲
```
適用：JavaScript 渲染的網頁
工具：Selenium + WebDriver
範例：電商網站、社交媒體
```

### 3. API 爬蟲
```
適用：提供 API 的網站
工具：requests + JSON
範例：GitHub、Twitter API
```

---

## 📂 測試資料說明

資料夾中提供了：

1. **sample_urls.txt** - 測試用網址清單
2. **scraper_template.py** - 爬蟲模板（可直接修改使用）
3. **results/** - 爬蟲結果儲存資料夾

---

## 🎯 挑戰任務

### 🥇 初級挑戰
- [ ] 抓取一個新聞網站的最新 10 則標題
- [ ] 下載網頁上的所有圖片
- [ ] 抓取表格資料並轉存為 CSV

### 🥈 中級挑戰
- [ ] 批次抓取多個網站的內容
- [ ] 建立價格監控機器人
- [ ] 抓取並分析評論情感

### 🥉 高級挑戰
- [ ] 建立自動化新聞彙整系統
- [ ] 爬取電商網站的商品比價
- [ ] 建立每日定時爬蟲並發送通知

---

## 🌟 小技巧

### 如何處理爬蟲常見問題

**問題 1：網頁載入很慢**
```
👤：網頁載入超過 30 秒，可以設定超時嗎？

🤖：當然！我會設定 timeout=10 秒
    超時就跳過這個網頁
```

**問題 2：被網站封鎖**
```
👤：出現 403 錯誤，是被封鎖了嗎？

🤖：可能是因為：
1. 請求太頻繁 → 加大延遲時間
2. 沒有 User-Agent → 加上瀏覽器標頭
3. 網站有反爬機制 → 需要更進階的方法
```

**問題 3：資料不完整**
```
👤：抓到的內容不完整，有些欄位是空的

🤖：可能原因：
1. 網頁是動態載入 → 改用 Selenium
2. 內容在 iframe 裡 → 需要特殊處理
3. 選擇器不正確 → 檢查 CSS Selector
```

---

## ⚖️ 法律與道德考量

使用爬蟲時請注意：

1. **個人資料保護**：不要抓取敏感個人資訊
2. **著作權**：尊重內容版權，僅供個人學習
3. **使用條款**：遵守網站的服務條款
4. **公平使用**：不要對伺服器造成過大負擔
5. **robots.txt**：遵守網站的爬蟲規則

---

記住：**做一個有禮貌的爬蟲工程師！** 🕷️
